{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCF241uNjXjY",
        "outputId": "27a2fe4f-022f-447f-eb00-289cab5efcfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9bf3U_ekHKg",
        "outputId": "3fb71919-f469-428d-9044-d9e7db59e3b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/semantic_mapping_project\n"
          ]
        }
      ],
      "source": [
        "%cd drive/MyDrive/semantic_mapping_project/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzPgchChkMTk",
        "outputId": "4ece9eb1-059e-4c78-8aaf-c46ab130db97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/9 [00:00<?, ?it/s]\n",
            "  0%|          | 0/18 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 99/99 [00:00<00:00, 186455.36it/s]\n",
            "\n",
            "  6%|▌         | 1/18 [00:00<00:06,  2.73it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 72/72 [00:00<00:00, 177536.68it/s]\n",
            "\n",
            " 11%|█         | 2/18 [00:00<00:06,  2.54it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 63/63 [00:00<00:00, 173728.57it/s]\n",
            "\n",
            " 17%|█▋        | 3/18 [00:01<00:05,  2.58it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 59/59 [00:00<00:00, 156030.22it/s]\n",
            "\n",
            " 22%|██▏       | 4/18 [00:01<00:05,  2.57it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 55/55 [00:00<00:00, 185439.49it/s]\n",
            "\n",
            " 28%|██▊       | 5/18 [00:01<00:04,  2.62it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 58/58 [00:00<00:00, 24285.68it/s]\n",
            "\n",
            " 33%|███▎      | 6/18 [00:02<00:04,  2.57it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 64/64 [00:00<00:00, 179916.53it/s]\n",
            "\n",
            " 39%|███▉      | 7/18 [00:02<00:04,  2.30it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 29/29 [00:00<00:00, 122987.68it/s]\n",
            "\n",
            " 44%|████▍     | 8/18 [00:03<00:04,  2.22it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 74/74 [00:00<00:00, 163615.44it/s]\n",
            "\n",
            " 50%|█████     | 9/18 [00:03<00:03,  2.26it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 121/121 [00:00<00:00, 29256.40it/s]\n",
            "\n",
            " 56%|█████▌    | 10/18 [00:04<00:03,  2.22it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 103/103 [00:00<00:00, 166479.12it/s]\n",
            "\n",
            " 61%|██████    | 11/18 [00:04<00:03,  2.30it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 191/191 [00:00<00:00, 201791.45it/s]\n",
            "\n",
            " 67%|██████▋   | 12/18 [00:05<00:02,  2.41it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 38/38 [00:00<00:00, 123457.44it/s]\n",
            "\n",
            " 72%|███████▏  | 13/18 [00:05<00:01,  2.55it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 101/101 [00:00<00:00, 173049.31it/s]\n",
            "\n",
            " 78%|███████▊  | 14/18 [00:05<00:01,  2.53it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 77/77 [00:00<00:00, 185078.17it/s]\n",
            "\n",
            " 83%|████████▎ | 15/18 [00:06<00:01,  2.54it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 46/46 [00:00<00:00, 82912.76it/s]\n",
            "\n",
            " 89%|████████▉ | 16/18 [00:06<00:00,  2.64it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 44/44 [00:00<00:00, 149796.57it/s]\n",
            "\n",
            " 94%|█████████▍| 17/18 [00:06<00:00,  2.74it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 88/88 [00:00<00:00, 177195.75it/s]\n",
            "\n",
            "100%|██████████| 18/18 [00:07<00:00,  2.48it/s]\n",
            " 11%|█         | 1/9 [00:07<01:02,  7.83s/it]\n",
            "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 42/42 [00:00<00:00, 136031.48it/s]\n",
            "\n",
            "  2%|▎         | 1/40 [00:00<00:14,  2.62it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 89/89 [00:00<00:00, 168074.32it/s]\n",
            "\n",
            "  5%|▌         | 2/40 [00:00<00:15,  2.46it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 45/45 [00:00<00:00, 220752.84it/s]\n",
            "\n",
            "  8%|▊         | 3/40 [00:01<00:17,  2.12it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 5/5 [00:00<00:00, 37991.88it/s]\n",
            "\n",
            " 10%|█         | 4/40 [00:01<00:16,  2.22it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 58/58 [00:00<00:00, 202051.19it/s]\n",
            "\n",
            " 12%|█▎        | 5/40 [00:02<00:15,  2.29it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 32/32 [00:00<00:00, 75786.41it/s]\n",
            "\n",
            " 15%|█▌        | 6/40 [00:02<00:14,  2.29it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 29/29 [00:00<00:00, 69985.51it/s]\n",
            "\n",
            " 18%|█▊        | 7/40 [00:03<00:14,  2.31it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 10/10 [00:00<00:00, 60262.99it/s]\n",
            "\n",
            " 20%|██        | 8/40 [00:03<00:13,  2.38it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 11/11 [00:00<00:00, 72315.59it/s]\n",
            "\n",
            " 22%|██▎       | 9/40 [00:03<00:12,  2.41it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 70/70 [00:00<00:00, 136305.14it/s]\n",
            "\n",
            " 25%|██▌       | 10/40 [00:04<00:11,  2.51it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 39/39 [00:00<00:00, 141748.58it/s]\n",
            "\n",
            " 28%|██▊       | 11/40 [00:04<00:11,  2.55it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 32/32 [00:00<00:00, 112034.83it/s]\n",
            "\n",
            " 30%|███       | 12/40 [00:04<00:10,  2.57it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 29/29 [00:00<00:00, 128987.08it/s]\n",
            "\n",
            " 32%|███▎      | 13/40 [00:05<00:10,  2.55it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 33/33 [00:00<00:00, 10493.71it/s]\n",
            "\n",
            " 35%|███▌      | 14/40 [00:05<00:09,  2.62it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 45/45 [00:00<00:00, 151967.54it/s]\n",
            "\n",
            " 38%|███▊      | 15/40 [00:06<00:09,  2.61it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 6/6 [00:00<00:00, 45507.82it/s]\n",
            "\n",
            " 40%|████      | 16/40 [00:06<00:09,  2.64it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 7/7 [00:00<00:00, 45449.11it/s]\n",
            "\n",
            " 42%|████▎     | 17/40 [00:06<00:08,  2.71it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 66/66 [00:00<00:00, 175649.79it/s]\n",
            "\n",
            " 45%|████▌     | 18/40 [00:07<00:08,  2.65it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 6/6 [00:00<00:00, 42509.84it/s]\n",
            "\n",
            " 48%|████▊     | 19/40 [00:07<00:07,  2.70it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 42/42 [00:00<00:00, 161319.38it/s]\n",
            "\n",
            " 50%|█████     | 20/40 [00:08<00:08,  2.50it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 42/42 [00:00<00:00, 93802.33it/s]\n",
            "\n",
            " 52%|█████▎    | 21/40 [00:08<00:07,  2.51it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 89/89 [00:00<00:00, 213554.38it/s]\n",
            "\n",
            " 55%|█████▌    | 22/40 [00:08<00:07,  2.53it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 45/45 [00:00<00:00, 138172.53it/s]\n",
            "\n",
            " 57%|█████▊    | 23/40 [00:09<00:06,  2.54it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 5/5 [00:00<00:00, 33934.50it/s]\n",
            "\n",
            " 60%|██████    | 24/40 [00:09<00:06,  2.58it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 58/58 [00:00<00:00, 100983.66it/s]\n",
            "\n",
            " 62%|██████▎   | 25/40 [00:09<00:05,  2.57it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 32/32 [00:00<00:00, 109834.47it/s]\n",
            "\n",
            " 65%|██████▌   | 26/40 [00:10<00:05,  2.61it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 29/29 [00:00<00:00, 127633.59it/s]\n",
            "\n",
            " 68%|██████▊   | 27/40 [00:10<00:05,  2.55it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 10/10 [00:00<00:00, 58092.85it/s]\n",
            "\n",
            " 70%|███████   | 28/40 [00:11<00:04,  2.54it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 11/11 [00:00<00:00, 65536.00it/s]\n",
            "\n",
            " 72%|███████▎  | 29/40 [00:11<00:04,  2.50it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 70/70 [00:00<00:00, 183157.38it/s]\n",
            "\n",
            " 75%|███████▌  | 30/40 [00:11<00:03,  2.54it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 39/39 [00:00<00:00, 139215.20it/s]\n",
            "\n",
            " 78%|███████▊  | 31/40 [00:12<00:03,  2.54it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 32/32 [00:00<00:00, 125086.42it/s]\n",
            "\n",
            " 80%|████████  | 32/40 [00:12<00:03,  2.46it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 29/29 [00:00<00:00, 112938.55it/s]\n",
            "\n",
            " 82%|████████▎ | 33/40 [00:13<00:02,  2.51it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 33/33 [00:00<00:00, 102300.10it/s]\n",
            "\n",
            " 85%|████████▌ | 34/40 [00:13<00:02,  2.59it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 45/45 [00:00<00:00, 109163.49it/s]\n",
            "\n",
            " 88%|████████▊ | 35/40 [00:13<00:01,  2.67it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 6/6 [00:00<00:00, 41943.04it/s]\n",
            "\n",
            " 90%|█████████ | 36/40 [00:14<00:01,  2.65it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 7/7 [00:00<00:00, 48289.68it/s]\n",
            "\n",
            " 92%|█████████▎| 37/40 [00:14<00:01,  2.68it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 66/66 [00:00<00:00, 169934.97it/s]\n",
            "\n",
            " 95%|█████████▌| 38/40 [00:15<00:00,  2.64it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 6/6 [00:00<00:00, 43996.20it/s]\n",
            "\n",
            " 98%|█████████▊| 39/40 [00:15<00:00,  2.66it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 42/42 [00:00<00:00, 147291.61it/s]\n",
            "\n",
            "100%|██████████| 40/40 [00:15<00:00,  2.54it/s]\n",
            " 22%|██▏       | 2/9 [00:24<01:30, 12.94s/it]\n",
            "  0%|          | 0/17 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 36/36 [00:00<00:00, 133270.03it/s]\n",
            "\n",
            "  6%|▌         | 1/17 [00:00<00:05,  2.79it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 23/23 [00:00<00:00, 126599.73it/s]\n",
            "\n",
            " 12%|█▏        | 2/17 [00:00<00:05,  2.71it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 33/33 [00:00<00:00, 128278.06it/s]\n",
            "\n",
            " 18%|█▊        | 3/17 [00:01<00:05,  2.75it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 36/36 [00:00<00:00, 131758.24it/s]\n",
            "\n",
            " 24%|██▎       | 4/17 [00:01<00:04,  2.73it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 33/33 [00:00<00:00, 179290.20it/s]\n",
            "\n",
            " 29%|██▉       | 5/17 [00:01<00:04,  2.72it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 24/24 [00:00<00:00, 82578.59it/s]\n",
            "\n",
            " 35%|███▌      | 6/17 [00:02<00:04,  2.62it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 36/36 [00:00<00:00, 124892.43it/s]\n",
            "\n",
            " 41%|████      | 7/17 [00:02<00:03,  2.62it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 50/50 [00:00<00:00, 145736.76it/s]\n",
            "\n",
            " 47%|████▋     | 8/17 [00:03<00:03,  2.61it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 38/38 [00:00<00:00, 141674.27it/s]\n",
            "\n",
            " 53%|█████▎    | 9/17 [00:03<00:02,  2.72it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 22/22 [00:00<00:00, 104265.18it/s]\n",
            "\n",
            " 59%|█████▉    | 10/17 [00:03<00:02,  2.84it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 20/20 [00:00<00:00, 97541.95it/s]\n",
            "\n",
            " 65%|██████▍   | 11/17 [00:04<00:02,  2.84it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 28/28 [00:00<00:00, 119959.66it/s]\n",
            "\n",
            " 71%|███████   | 12/17 [00:04<00:01,  2.90it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 23/23 [00:00<00:00, 105777.40it/s]\n",
            "\n",
            " 76%|███████▋  | 13/17 [00:04<00:01,  2.79it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 61/61 [00:00<00:00, 162342.98it/s]\n",
            "\n",
            " 82%|████████▏ | 14/17 [00:05<00:01,  2.68it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 24/24 [00:00<00:00, 110376.42it/s]\n",
            "\n",
            " 88%|████████▊ | 15/17 [00:05<00:00,  2.68it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 6/6 [00:00<00:00, 37843.34it/s]\n",
            "\n",
            " 94%|█████████▍| 16/17 [00:05<00:00,  2.69it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 23/23 [00:00<00:00, 111653.93it/s]\n",
            "\n",
            "100%|██████████| 17/17 [00:06<00:00,  2.71it/s]\n",
            " 33%|███▎      | 3/9 [00:30<01:00, 10.06s/it]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 197/197 [00:00<00:00, 217613.35it/s]\n",
            "\n",
            "  5%|▌         | 1/20 [00:00<00:07,  2.68it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 19/19 [00:00<00:00, 106255.70it/s]\n",
            "\n",
            " 10%|█         | 2/20 [00:00<00:06,  2.73it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 28/28 [00:00<00:00, 145707.83it/s]\n",
            "\n",
            " 15%|█▌        | 3/20 [00:01<00:06,  2.72it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 14/14 [00:00<00:00, 74707.70it/s]\n",
            "\n",
            " 20%|██        | 4/20 [00:01<00:05,  2.78it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 43/43 [00:00<00:00, 99205.21it/s]\n",
            "\n",
            " 25%|██▌       | 5/20 [00:01<00:05,  2.84it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 11/11 [00:00<00:00, 45862.17it/s]\n",
            "\n",
            " 30%|███       | 6/20 [00:02<00:05,  2.71it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 17/17 [00:00<00:00, 95708.95it/s]\n",
            "\n",
            " 35%|███▌      | 7/20 [00:02<00:04,  2.75it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 36/36 [00:00<00:00, 124789.21it/s]\n",
            "\n",
            " 40%|████      | 8/20 [00:02<00:04,  2.81it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 37/37 [00:00<00:00, 143295.70it/s]\n",
            "\n",
            " 45%|████▌     | 9/20 [00:03<00:03,  2.83it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 52/52 [00:00<00:00, 156458.97it/s]\n",
            "\n",
            " 50%|█████     | 10/20 [00:03<00:03,  2.77it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 29/29 [00:00<00:00, 115184.48it/s]\n",
            "\n",
            " 55%|█████▌    | 11/20 [00:03<00:03,  2.77it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 128/128 [00:00<00:00, 208250.94it/s]\n",
            "\n",
            " 60%|██████    | 12/20 [00:04<00:02,  2.78it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 41/41 [00:00<00:00, 17754.13it/s]\n",
            "\n",
            " 65%|██████▌   | 13/20 [00:04<00:02,  2.82it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 192/192 [00:00<00:00, 210427.59it/s]\n",
            "\n",
            " 70%|███████   | 14/20 [00:05<00:02,  2.75it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 18/18 [00:00<00:00, 83700.08it/s]\n",
            "\n",
            " 75%|███████▌  | 15/20 [00:05<00:01,  2.72it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 21/21 [00:00<00:00, 158703.39it/s]\n",
            "\n",
            " 80%|████████  | 16/20 [00:05<00:01,  2.75it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 14/14 [00:00<00:00, 83173.17it/s]\n",
            "\n",
            " 85%|████████▌ | 17/20 [00:06<00:01,  2.81it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 64/64 [00:00<00:00, 183608.38it/s]\n",
            "\n",
            " 90%|█████████ | 18/20 [00:06<00:00,  2.86it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 29/29 [00:00<00:00, 133079.67it/s]\n",
            "\n",
            " 95%|█████████▌| 19/20 [00:06<00:00,  2.92it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 21/21 [00:00<00:00, 104608.53it/s]\n",
            "\n",
            "100%|██████████| 20/20 [00:07<00:00,  2.78it/s]\n",
            " 44%|████▍     | 4/9 [00:38<00:45,  9.05s/it]\n",
            "  0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 15/15 [00:00<00:00, 131620.42it/s]\n",
            "\n",
            "  4%|▍         | 1/24 [00:00<00:08,  2.67it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 21/21 [00:00<00:00, 93206.76it/s]\n",
            "\n",
            "  8%|▊         | 2/24 [00:00<00:07,  2.80it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 31/31 [00:00<00:00, 129505.40it/s]\n",
            "\n",
            " 12%|█▎        | 3/24 [00:01<00:07,  2.83it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 17/17 [00:00<00:00, 92721.93it/s]\n",
            "\n",
            " 17%|█▋        | 4/24 [00:01<00:07,  2.70it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 31/31 [00:00<00:00, 125869.72it/s]\n",
            "\n",
            " 21%|██        | 5/24 [00:01<00:06,  2.72it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 15/15 [00:00<00:00, 79840.81it/s]\n",
            "\n",
            " 25%|██▌       | 6/24 [00:02<00:06,  2.77it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 18/18 [00:00<00:00, 88095.07it/s]\n",
            "\n",
            " 29%|██▉       | 7/24 [00:02<00:06,  2.69it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 49/49 [00:00<00:00, 173435.36it/s]\n",
            "\n",
            " 33%|███▎      | 8/24 [00:02<00:05,  2.70it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 20/20 [00:00<00:00, 103054.15it/s]\n",
            "\n",
            " 38%|███▊      | 9/24 [00:03<00:05,  2.68it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 40/40 [00:00<00:00, 139577.50it/s]\n",
            "\n",
            " 42%|████▏     | 10/24 [00:03<00:05,  2.63it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 10/10 [00:00<00:00, 61052.46it/s]\n",
            "\n",
            " 46%|████▌     | 11/24 [00:04<00:04,  2.65it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 15/15 [00:00<00:00, 94466.31it/s]\n",
            "\n",
            " 50%|█████     | 12/24 [00:04<00:04,  2.60it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 18/18 [00:00<00:00, 48395.82it/s]\n",
            "\n",
            " 54%|█████▍    | 13/24 [00:04<00:04,  2.56it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 15/15 [00:00<00:00, 87869.50it/s]\n",
            "\n",
            " 58%|█████▊    | 14/24 [00:05<00:04,  2.48it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 21/21 [00:00<00:00, 114093.76it/s]\n",
            "\n",
            " 62%|██████▎   | 15/24 [00:05<00:03,  2.53it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 20/20 [00:00<00:00, 102927.71it/s]\n",
            "\n",
            " 67%|██████▋   | 16/24 [00:06<00:03,  2.49it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 40/40 [00:00<00:00, 175861.80it/s]\n",
            "\n",
            " 71%|███████   | 17/24 [00:06<00:03,  2.31it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 15/15 [00:00<00:00, 77006.81it/s]\n",
            "\n",
            " 75%|███████▌  | 18/24 [00:06<00:02,  2.52it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 10/10 [00:00<00:00, 60523.87it/s]\n",
            "\n",
            " 79%|███████▉  | 19/24 [00:07<00:01,  2.52it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 49/49 [00:00<00:00, 24102.37it/s]\n",
            "\n",
            " 83%|████████▎ | 20/24 [00:07<00:01,  2.59it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 17/17 [00:00<00:00, 90143.07it/s]\n",
            "\n",
            " 88%|████████▊ | 21/24 [00:08<00:01,  2.62it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 15/15 [00:00<00:00, 78545.02it/s]\n",
            "\n",
            " 92%|█████████▏| 22/24 [00:08<00:00,  2.65it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 9/9 [00:00<00:00, 57108.53it/s]\n",
            "\n",
            " 96%|█████████▌| 23/24 [00:08<00:00,  2.65it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 9/9 [00:00<00:00, 61082.10it/s]\n",
            "\n",
            "100%|██████████| 24/24 [00:09<00:00,  2.62it/s]\n",
            " 56%|█████▌    | 5/9 [00:48<00:36,  9.22s/it]\n",
            "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 50/50 [00:00<00:00, 152188.10it/s]\n",
            "\n",
            "  2%|▎         | 1/40 [00:00<00:14,  2.66it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 28/28 [00:00<00:00, 114130.72it/s]\n",
            "\n",
            "  5%|▌         | 2/40 [00:00<00:15,  2.52it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 10/10 [00:00<00:00, 3748.26it/s]\n",
            "\n",
            "  8%|▊         | 3/40 [00:01<00:13,  2.66it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 50/50 [00:00<00:00, 163968.10it/s]\n",
            "\n",
            " 10%|█         | 4/40 [00:01<00:13,  2.61it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 44/44 [00:00<00:00, 142289.42it/s]\n",
            "\n",
            " 12%|█▎        | 5/40 [00:01<00:13,  2.56it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 23/23 [00:00<00:00, 101760.54it/s]\n",
            "\n",
            " 15%|█▌        | 6/40 [00:02<00:13,  2.60it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 5/5 [00:00<00:00, 31920.12it/s]\n",
            "\n",
            " 18%|█▊        | 7/40 [00:02<00:12,  2.68it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 35/35 [00:00<00:00, 135549.99it/s]\n",
            "\n",
            " 20%|██        | 8/40 [00:03<00:12,  2.52it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 32/32 [00:00<00:00, 63310.25it/s]\n",
            "\n",
            " 22%|██▎       | 9/40 [00:03<00:12,  2.39it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 54/54 [00:00<00:00, 153450.15it/s]\n",
            "\n",
            " 25%|██▌       | 10/40 [00:03<00:11,  2.54it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 30/30 [00:00<00:00, 115651.76it/s]\n",
            "\n",
            " 28%|██▊       | 11/40 [00:04<00:11,  2.61it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 44/44 [00:00<00:00, 144404.83it/s]\n",
            "\n",
            " 30%|███       | 12/40 [00:04<00:10,  2.68it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 10/10 [00:00<00:00, 65948.18it/s]\n",
            "\n",
            " 32%|███▎      | 13/40 [00:04<00:09,  2.72it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 5/5 [00:00<00:00, 35726.61it/s]\n",
            "\n",
            " 35%|███▌      | 14/40 [00:05<00:09,  2.63it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 28/28 [00:00<00:00, 123882.40it/s]\n",
            "\n",
            " 38%|███▊      | 15/40 [00:05<00:10,  2.48it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 23/23 [00:00<00:00, 96662.32it/s]\n",
            "\n",
            " 40%|████      | 16/40 [00:06<00:10,  2.35it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 29/29 [00:00<00:00, 118206.82it/s]\n",
            "\n",
            " 42%|████▎     | 17/40 [00:06<00:09,  2.30it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 38/38 [00:00<00:00, 133823.30it/s]\n",
            "\n",
            " 45%|████▌     | 18/40 [00:07<00:09,  2.21it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 32/32 [00:00<00:00, 156067.13it/s]\n",
            "\n",
            " 48%|████▊     | 19/40 [00:07<00:09,  2.19it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 54/54 [00:00<00:00, 159614.11it/s]\n",
            "\n",
            " 50%|█████     | 20/40 [00:08<00:08,  2.38it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 39/39 [00:00<00:00, 150624.18it/s]\n",
            "\n",
            " 52%|█████▎    | 21/40 [00:08<00:08,  2.21it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 39/39 [00:00<00:00, 133751.31it/s]\n",
            "\n",
            " 55%|█████▌    | 22/40 [00:09<00:08,  2.22it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 28/28 [00:00<00:00, 119350.11it/s]\n",
            "\n",
            " 57%|█████▊    | 23/40 [00:09<00:07,  2.36it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 44/44 [00:00<00:00, 145888.83it/s]\n",
            "\n",
            " 60%|██████    | 24/40 [00:09<00:06,  2.29it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 46/46 [00:00<00:00, 134639.21it/s]\n",
            "\n",
            " 62%|██████▎   | 25/40 [00:10<00:06,  2.26it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 60/60 [00:00<00:00, 154676.24it/s]\n",
            "\n",
            " 65%|██████▌   | 26/40 [00:10<00:05,  2.51it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 23/23 [00:00<00:00, 104290.80it/s]\n",
            "\n",
            " 68%|██████▊   | 27/40 [00:10<00:05,  2.60it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 28/28 [00:00<00:00, 111212.61it/s]\n",
            "\n",
            " 70%|███████   | 28/40 [00:11<00:04,  2.45it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 63/63 [00:00<00:00, 150822.58it/s]\n",
            "\n",
            " 72%|███████▎  | 29/40 [00:11<00:04,  2.51it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 10/10 [00:00<00:00, 58991.62it/s]\n",
            "\n",
            " 75%|███████▌  | 30/40 [00:12<00:04,  2.40it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 10/10 [00:00<00:00, 48657.82it/s]\n",
            "\n",
            " 78%|███████▊  | 31/40 [00:12<00:03,  2.47it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 60/60 [00:00<00:00, 153919.41it/s]\n",
            "\n",
            " 80%|████████  | 32/40 [00:13<00:03,  2.39it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 30/30 [00:00<00:00, 54283.49it/s]\n",
            "\n",
            " 82%|████████▎ | 33/40 [00:13<00:03,  2.26it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 38/38 [00:00<00:00, 154441.43it/s]\n",
            "\n",
            " 85%|████████▌ | 34/40 [00:13<00:02,  2.37it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 63/63 [00:00<00:00, 175342.50it/s]\n",
            "\n",
            " 88%|████████▊ | 35/40 [00:14<00:02,  2.31it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 23/23 [00:00<00:00, 111267.58it/s]\n",
            "\n",
            " 90%|█████████ | 36/40 [00:14<00:01,  2.42it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 46/46 [00:00<00:00, 141450.13it/s]\n",
            "\n",
            " 92%|█████████▎| 37/40 [00:15<00:01,  2.36it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 35/35 [00:00<00:00, 142386.65it/s]\n",
            "\n",
            " 95%|█████████▌| 38/40 [00:15<00:00,  2.41it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 44/44 [00:00<00:00, 104917.21it/s]\n",
            "\n",
            " 98%|█████████▊| 39/40 [00:16<00:00,  2.50it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 29/29 [00:00<00:00, 108602.51it/s]\n",
            "\n",
            "100%|██████████| 40/40 [00:16<00:00,  2.43it/s]\n",
            " 67%|██████▋   | 6/9 [01:05<00:35, 11.87s/it]\n",
            "  0%|          | 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 9/9 [00:00<00:00, 62705.54it/s]\n",
            "\n",
            "  5%|▌         | 1/19 [00:00<00:07,  2.25it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 18/18 [00:00<00:00, 96915.88it/s]\n",
            "\n",
            " 11%|█         | 2/19 [00:00<00:06,  2.54it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 17/17 [00:00<00:00, 127554.86it/s]\n",
            "\n",
            " 16%|█▌        | 3/19 [00:01<00:06,  2.36it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 23/23 [00:00<00:00, 112434.72it/s]\n",
            "\n",
            " 21%|██        | 4/19 [00:01<00:06,  2.30it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 12/12 [00:00<00:00, 72211.83it/s]\n",
            "\n",
            " 26%|██▋       | 5/19 [00:02<00:05,  2.47it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 66/66 [00:00<00:00, 165564.63it/s]\n",
            "\n",
            " 32%|███▏      | 6/19 [00:02<00:05,  2.30it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 14/14 [00:00<00:00, 89786.32it/s]\n",
            "\n",
            " 37%|███▋      | 7/19 [00:02<00:04,  2.41it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 20/20 [00:00<00:00, 105649.97it/s]\n",
            "\n",
            " 42%|████▏     | 8/19 [00:03<00:04,  2.53it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 12/12 [00:00<00:00, 70099.79it/s]\n",
            "\n",
            " 47%|████▋     | 9/19 [00:03<00:03,  2.62it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 23/23 [00:00<00:00, 80123.75it/s]\n",
            "\n",
            " 53%|█████▎    | 10/19 [00:04<00:03,  2.34it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 62/62 [00:00<00:00, 154238.94it/s]\n",
            "\n",
            " 58%|█████▊    | 11/19 [00:04<00:03,  2.40it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 20/20 [00:00<00:00, 105916.77it/s]\n",
            "\n",
            " 63%|██████▎   | 12/19 [00:05<00:02,  2.33it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 21/21 [00:00<00:00, 94002.54it/s]\n",
            "\n",
            " 68%|██████▊   | 13/19 [00:05<00:02,  2.16it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 21/21 [00:00<00:00, 109963.03it/s]\n",
            "\n",
            " 74%|███████▎  | 14/19 [00:06<00:02,  2.15it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 22/22 [00:00<00:00, 112393.04it/s]\n",
            "\n",
            " 79%|███████▉  | 15/19 [00:06<00:01,  2.06it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 13/13 [00:00<00:00, 50958.83it/s]\n",
            "\n",
            " 84%|████████▍ | 16/19 [00:06<00:01,  2.24it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 68/68 [00:00<00:00, 140706.79it/s]\n",
            "\n",
            " 89%|████████▉ | 17/19 [00:07<00:00,  2.24it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 26/26 [00:00<00:00, 159432.61it/s]\n",
            "\n",
            " 95%|█████████▍| 18/19 [00:07<00:00,  2.20it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 42/42 [00:00<00:00, 154798.57it/s]\n",
            "\n",
            "100%|██████████| 19/19 [00:08<00:00,  2.29it/s]\n",
            " 78%|███████▊  | 7/9 [01:13<00:21, 10.81s/it]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 17/17 [00:00<00:00, 48243.01it/s]\n",
            "\n",
            "  3%|▎         | 1/30 [00:00<00:10,  2.89it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 33/33 [00:00<00:00, 135565.16it/s]\n",
            "\n",
            "  7%|▋         | 2/30 [00:00<00:10,  2.77it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 8/8 [00:00<00:00, 57952.39it/s]\n",
            "\n",
            " 10%|█         | 3/30 [00:01<00:09,  2.80it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 66/66 [00:00<00:00, 109459.89it/s]\n",
            "\n",
            " 13%|█▎        | 4/30 [00:01<00:09,  2.75it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 45/45 [00:00<00:00, 146653.99it/s]\n",
            "\n",
            " 17%|█▋        | 5/30 [00:01<00:08,  2.87it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 9/9 [00:00<00:00, 59353.36it/s]\n",
            "\n",
            " 20%|██        | 6/30 [00:02<00:08,  2.83it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 5/5 [00:00<00:00, 34836.41it/s]\n",
            "\n",
            " 23%|██▎       | 7/30 [00:02<00:08,  2.79it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 33/33 [00:00<00:00, 134904.51it/s]\n",
            "\n",
            " 27%|██▋       | 8/30 [00:02<00:08,  2.72it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 50/50 [00:00<00:00, 143346.00it/s]\n",
            "\n",
            " 30%|███       | 9/30 [00:03<00:07,  2.68it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 46/46 [00:00<00:00, 148986.86it/s]\n",
            "\n",
            " 33%|███▎      | 10/30 [00:03<00:07,  2.72it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 45/45 [00:00<00:00, 161181.62it/s]\n",
            "\n",
            " 37%|███▋      | 11/30 [00:03<00:06,  2.75it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 98/98 [00:00<00:00, 177402.59it/s]\n",
            "\n",
            " 40%|████      | 12/30 [00:04<00:06,  2.64it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 16/16 [00:00<00:00, 80369.90it/s]\n",
            "\n",
            " 43%|████▎     | 13/30 [00:04<00:06,  2.72it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 8/8 [00:00<00:00, 56205.08it/s]\n",
            "\n",
            " 47%|████▋     | 14/30 [00:05<00:05,  2.68it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 47/47 [00:00<00:00, 154613.56it/s]\n",
            "\n",
            " 50%|█████     | 15/30 [00:05<00:05,  2.76it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 98/98 [00:00<00:00, 240656.79it/s]\n",
            "\n",
            " 53%|█████▎    | 16/30 [00:05<00:05,  2.70it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 26/26 [00:00<00:00, 119052.30it/s]\n",
            "\n",
            " 57%|█████▋    | 17/30 [00:06<00:04,  2.61it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 9/9 [00:00<00:00, 60494.77it/s]\n",
            "\n",
            " 60%|██████    | 18/30 [00:06<00:04,  2.57it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 16/16 [00:00<00:00, 83572.68it/s]\n",
            "\n",
            " 63%|██████▎   | 19/30 [00:07<00:04,  2.53it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 31/31 [00:00<00:00, 132541.72it/s]\n",
            "\n",
            " 67%|██████▋   | 20/30 [00:07<00:03,  2.57it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 20/20 [00:00<00:00, 103691.08it/s]\n",
            "\n",
            " 70%|███████   | 21/30 [00:07<00:03,  2.58it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 10/10 [00:00<00:00, 59918.63it/s]\n",
            "\n",
            " 73%|███████▎  | 22/30 [00:08<00:03,  2.59it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 66/66 [00:00<00:00, 178826.91it/s]\n",
            "\n",
            " 77%|███████▋  | 23/30 [00:08<00:02,  2.59it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 50/50 [00:00<00:00, 162822.36it/s]\n",
            "\n",
            " 80%|████████  | 24/30 [00:08<00:02,  2.61it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 5/5 [00:00<00:00, 34155.57it/s]\n",
            "\n",
            " 83%|████████▎ | 25/30 [00:09<00:01,  2.72it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 10/10 [00:00<00:00, 66260.73it/s]\n",
            "\n",
            " 87%|████████▋ | 26/30 [00:09<00:01,  2.76it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 63/63 [00:00<00:00, 155619.05it/s]\n",
            "\n",
            " 90%|█████████ | 27/30 [00:10<00:01,  2.70it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 17/17 [00:00<00:00, 73812.80it/s]\n",
            "\n",
            " 93%|█████████▎| 28/30 [00:10<00:00,  2.69it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 31/31 [00:00<00:00, 123831.83it/s]\n",
            "\n",
            " 97%|█████████▋| 29/30 [00:10<00:00,  2.79it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 9/9 [00:00<00:00, 57456.22it/s]\n",
            "\n",
            "100%|██████████| 30/30 [00:11<00:00,  2.68it/s]\n",
            " 89%|████████▉ | 8/9 [01:25<00:11, 11.07s/it]\n",
            "  0%|          | 0/36 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 47/47 [00:00<00:00, 144525.14it/s]\n",
            "\n",
            "  3%|▎         | 1/36 [00:00<00:12,  2.77it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 30/30 [00:00<00:00, 111947.62it/s]\n",
            "\n",
            "  6%|▌         | 2/36 [00:00<00:13,  2.50it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 23/23 [00:00<00:00, 126932.88it/s]\n",
            "\n",
            "  8%|▊         | 3/36 [00:01<00:12,  2.62it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 42/42 [00:00<00:00, 148784.43it/s]\n",
            "\n",
            " 11%|█         | 4/36 [00:01<00:11,  2.74it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 41/41 [00:00<00:00, 132078.70it/s]\n",
            "\n",
            " 14%|█▍        | 5/36 [00:01<00:11,  2.77it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 54/54 [00:00<00:00, 163061.49it/s]\n",
            "\n",
            " 17%|█▋        | 6/36 [00:02<00:10,  2.83it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 24/24 [00:00<00:00, 119552.61it/s]\n",
            "\n",
            " 19%|█▉        | 7/36 [00:02<00:10,  2.80it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 22/22 [00:00<00:00, 114342.86it/s]\n",
            "\n",
            " 22%|██▏       | 8/36 [00:02<00:10,  2.61it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 45/45 [00:00<00:00, 155472.55it/s]\n",
            "\n",
            " 25%|██▌       | 9/36 [00:03<00:10,  2.65it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 37/37 [00:00<00:00, 140062.50it/s]\n",
            "\n",
            " 28%|██▊       | 10/36 [00:03<00:10,  2.58it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 23/23 [00:00<00:00, 108149.09it/s]\n",
            "\n",
            " 31%|███       | 11/36 [00:04<00:09,  2.74it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 51/51 [00:00<00:00, 138992.53it/s]\n",
            "\n",
            " 33%|███▎      | 12/36 [00:04<00:08,  2.70it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 61/61 [00:00<00:00, 167333.25it/s]\n",
            "\n",
            " 36%|███▌      | 13/36 [00:04<00:08,  2.71it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 45/45 [00:00<00:00, 151358.20it/s]\n",
            "\n",
            " 39%|███▉      | 14/36 [00:05<00:08,  2.75it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 43/43 [00:00<00:00, 121369.50it/s]\n",
            "\n",
            " 42%|████▏     | 15/36 [00:05<00:07,  2.85it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 26/26 [00:00<00:00, 58472.87it/s]\n",
            "\n",
            " 44%|████▍     | 16/36 [00:05<00:07,  2.81it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 24/24 [00:00<00:00, 136770.78it/s]\n",
            "\n",
            " 47%|████▋     | 17/36 [00:06<00:06,  2.74it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 34/34 [00:00<00:00, 136204.71it/s]\n",
            "\n",
            " 50%|█████     | 18/36 [00:06<00:06,  2.77it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 93/93 [00:00<00:00, 187173.83it/s]\n",
            "\n",
            " 53%|█████▎    | 19/36 [00:06<00:06,  2.77it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 41/41 [00:00<00:00, 237522.74it/s]\n",
            "\n",
            " 56%|█████▌    | 20/36 [00:07<00:05,  2.68it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 73/73 [00:00<00:00, 123163.39it/s]\n",
            "\n",
            " 58%|█████▊    | 21/36 [00:07<00:05,  2.61it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 22/22 [00:00<00:00, 104738.58it/s]\n",
            "\n",
            " 61%|██████    | 22/36 [00:08<00:05,  2.62it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 30/30 [00:00<00:00, 120410.64it/s]\n",
            "\n",
            " 64%|██████▍   | 23/36 [00:08<00:04,  2.75it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 51/51 [00:00<00:00, 55589.79it/s]\n",
            "\n",
            " 67%|██████▋   | 24/36 [00:08<00:04,  2.86it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 34/34 [00:00<00:00, 123148.82it/s]\n",
            "\n",
            " 69%|██████▉   | 25/36 [00:09<00:04,  2.71it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 54/54 [00:00<00:00, 126109.36it/s]\n",
            "\n",
            " 72%|███████▏  | 26/36 [00:09<00:03,  2.70it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 42/42 [00:00<00:00, 142755.89it/s]\n",
            "\n",
            " 75%|███████▌  | 27/36 [00:09<00:03,  2.77it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 61/61 [00:00<00:00, 172175.33it/s]\n",
            "\n",
            " 78%|███████▊  | 28/36 [00:10<00:02,  2.73it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 93/93 [00:00<00:00, 119506.82it/s]\n",
            "\n",
            " 81%|████████  | 29/36 [00:10<00:02,  2.70it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 37/37 [00:00<00:00, 123953.07it/s]\n",
            "\n",
            " 83%|████████▎ | 30/36 [00:11<00:02,  2.69it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 51/51 [00:00<00:00, 148445.18it/s]\n",
            "\n",
            " 86%|████████▌ | 31/36 [00:11<00:01,  2.69it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 51/51 [00:00<00:00, 141661.92it/s]\n",
            "\n",
            " 89%|████████▉ | 32/36 [00:11<00:01,  2.69it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 26/26 [00:00<00:00, 110712.59it/s]\n",
            "\n",
            " 92%|█████████▏| 33/36 [00:12<00:01,  2.61it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 73/73 [00:00<00:00, 232839.69it/s]\n",
            "\n",
            " 94%|█████████▍| 34/36 [00:12<00:00,  2.70it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 43/43 [00:00<00:00, 125159.66it/s]\n",
            "\n",
            " 97%|█████████▋| 35/36 [00:12<00:00,  2.67it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 47/47 [00:00<00:00, 178885.92it/s]\n",
            "\n",
            "100%|██████████| 36/36 [00:13<00:00,  2.71it/s]\n",
            "100%|██████████| 9/9 [01:39<00:00, 11.02s/it]\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "tt_data = {\n",
        "          'house_id': [],\n",
        "          'file_name': [],\n",
        "          'frames_dir': [],\n",
        "          'target_obj': [],\n",
        "          'action': [],\n",
        "          'human_intention': [],\n",
        "          'gpt3_intension_wd': []\n",
        "      }\n",
        "\n",
        "for folder_name in tqdm(glob.glob(\"./\"+\"**_expert_annotations\",recursive=True)):\n",
        "  for file_name in tqdm(glob.glob(folder_name+\"/\"+\"forTraining/house_**_**.json\",recursive=True)):\n",
        "    with open(file_name, 'r') as f:\n",
        "      data = json.load(f)\n",
        "    target_object_type = data['target_object_type']\n",
        "    counter = 0\n",
        "    for ac_id in tqdm(range(len(data['actions']))):\n",
        "    \n",
        "      tt_data['house_id'].append(data['house_id'])\n",
        "      tt_data['file_name'].append(file_name.strip('.json'))\n",
        "      tt_data['frames_dir'].append(data['frames_dir'] + \"frame_\"+ str(counter))\n",
        "      tt_data['target_obj'].append(data['target_object_type'])\n",
        "      tt_data['action'].append(data['actions'][ac_id]['action'])\n",
        "      tt_data['human_intention'].append(data['actions'][ac_id]['intentions'])\n",
        "      tt_data['gpt3_intension_wd'].append(data['actions'][ac_id]['gpt3_intention_wd'])\n",
        "\n",
        "      counter += 1\n",
        "\n",
        "df = pd.DataFrame(data=tt_data)\n",
        "df['frame_count'] = df['frames_dir'].apply(lambda x: int(x.split('_')[-1]))\n",
        "df['Without_direction'] = df['file_name'].apply(lambda x: '_' == x[-1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['target_obj'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-WX4OHVosSy",
        "outputId": "8459c6b3-8324-402c-d971-9239891cd8db"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Book', 'Pillow', 'SprayBottle', 'Mug', 'Apple', 'Bowl',\n",
              "       'RemoteControl', 'Laptop', 'Pen', 'AlarmClock'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjfgL9ZlnBSi"
      },
      "outputs": [],
      "source": [
        "df = df[(df['action'] != 'PickUpObject') & (df['action'] != 'OpenObject') & (df['action'] != 'end') & (df['action'] != 'LookDown') & (df['action'] != 'LookUp')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ve9USWS3utJC"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "le = LabelEncoder()\n",
        "\n",
        "df['folder_name'] = df['file_name'].apply(lambda x: x.split('/')[1] + \"/\")\n",
        "df['image_path'] = df['folder_name'] + df['frames_dir'].apply(lambda x : \"/\".join(x.split('/')[1:]))\n",
        "df['label'] = le.fit_transform(list(df['action']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQhJKotzLtOS",
        "outputId": "d897ec39-8b38-4441-8225-a07c787d2498"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['MoveAhead', 'MoveBack', 'MoveLeft', 'MoveRight', 'RotateLeft',\n",
              "       'RotateRight'], dtype='<U11')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "le.classes_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_4Q_n-iLgmn",
        "outputId": "a8bb0833-e486-4217-fcd2-afa556c2c502"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    6294\n",
              "5     684\n",
              "3     613\n",
              "4     590\n",
              "2     515\n",
              "1      22\n",
              "Name: label, dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XpyFxl_0YE5"
      },
      "outputs": [],
      "source": [
        "df.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERQdRGRDof-t"
      },
      "outputs": [],
      "source": [
        "train_col = ['gpt3_intension_wd', 'image_path']\n",
        "target_col = ['action']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2NtwFUxo2e7"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_train, df_val = train_test_split(df, test_size=0.2, random_state= 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S53MOmEMi4Gv"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "from torchvision import models, transforms\n",
        "import numpy as np\n",
        "import transformers\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "from PIL import Image\n",
        "from skimage import io, transform\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from transformers import BertModel, BertTokenizer\n",
        "import random\n",
        "import time\n",
        "import os\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from torch.utils.tensorboard import SummaryWriter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJaNKam6i3aA",
        "outputId": "ac7bdf6c-7e71-4cc4-9885-3b612ca74c07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlcAVfrKR-o9"
      },
      "outputs": [],
      "source": [
        "class TextEncoder(nn.Module):\n",
        "\n",
        "    def __init__(self, text_fc2_out=32, text_fc1_out=128, dropout_p=0.4, fine_tune_module=False):\n",
        "        super(TextEncoder, self).__init__()\n",
        "        self.fine_tune_module = fine_tune_module\n",
        "\n",
        "        # Instantiate BERT model\n",
        "        self.bert = BertModel.from_pretrained(\n",
        "                    'bert-base-uncased',\n",
        "                    return_dict=True)\n",
        "\n",
        "        self.text_enc_fc1 = torch.nn.Linear(768, text_fc1_out)\n",
        "        self.text_enc_fc2 = torch.nn.Linear(text_fc1_out, text_fc2_out)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "        self.fine_tune()\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        \n",
        "        # Feed input to BERT\n",
        "        out = self.bert(input_ids=input_ids,\n",
        "                            attention_mask=attention_mask)\n",
        "        \n",
        "        ## odict_keys(['last_hidden_state', 'pooler_output', 'attentions'])\n",
        "        ## last_hidden_state (torch.FloatTensor of shape (batch_size, sequence_length, hidden_size)) \n",
        "\n",
        "        x = self.dropout(\n",
        "            torch.nn.functional.relu(\n",
        "                self.text_enc_fc1(out['pooler_output']))\n",
        "        )    \n",
        "\n",
        "        x = self.dropout(\n",
        "            torch.nn.functional.relu(\n",
        "                self.text_enc_fc2(x))\n",
        "        ) \n",
        "        \n",
        "        return x\n",
        "    \n",
        "    def fine_tune(self):\n",
        "        \"\"\"\n",
        "        keep the weights fixed or not  \n",
        "        \"\"\"\n",
        "        for p in self.bert.parameters():\n",
        "            p.requires_grad = self.fine_tune_module\n",
        "            \n",
        "\n",
        "            \n",
        "class VisionEncoder(nn.Module):\n",
        "    \"\"\"Visual Feature extraction\n",
        "    \"\"\"\n",
        "    def __init__(self, img_fc1_out=128, img_fc2_out=32, dropout_p=0.4, fine_tune_module=False):\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        super(VisionEncoder, self).__init__()\n",
        "        \n",
        "        self.fine_tune_module = fine_tune_module\n",
        "\n",
        "        \n",
        "        self.resnet = models.resnet50(pretrained=True)\n",
        "        num_ftrs = self.resnet.fc.in_features\n",
        "        self.resnet.fc = nn.Linear(num_ftrs, img_fc1_out)\n",
        "  \n",
        "        self.vis_encoder = self.resnet\n",
        "\n",
        "        self.vis_enc_fc2 = torch.nn.Linear(img_fc1_out, img_fc2_out)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "        self.fine_tune()\n",
        "        \n",
        "\n",
        "        \n",
        "    def forward(self, images):\n",
        "        \"\"\"\n",
        "        Forward propagation.\n",
        "        :param images: images, a tensor of dimensions (batch_size, 3, image_size, image_size)\n",
        "        :return: encoded images\n",
        "        \"\"\"\n",
        "\n",
        "        x = self.vis_encoder(images)\n",
        "\n",
        "        x = self.dropout(\n",
        "            torch.nn.functional.relu(\n",
        "                self.vis_enc_fc2(x))\n",
        "        )\n",
        "\n",
        "        return x\n",
        "    \n",
        "    def fine_tune(self):\n",
        "        \"\"\"\n",
        "        Allow or prevent the computation of gradients for convolutional blocks 2 through 4 of the encoder.\n",
        "        :param fine_tune: Allow?\n",
        "        \"\"\"\n",
        "        for p in self.resnet.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "        # If fine-tuning, only fine-tune convolutional blocks 2 through 4\n",
        "        for c in list(self.resnet.children())[5:]:\n",
        "            for p in c.parameters():\n",
        "                p.requires_grad = self.fine_tune_module\n",
        "                \n",
        "class LanguageAndVisionConcat(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        model_params\n",
        "        \n",
        "    ):\n",
        "        super(LanguageAndVisionConcat, self).__init__()\n",
        "        \n",
        "        self.text_encoder = TextEncoder(model_params['text_fc2_out'], model_params['text_fc1_out'], model_params['dropout_p'], model_params['fine_tune_text_module'])\n",
        "        self.vision_encode = VisionEncoder(model_params['img_fc1_out'], model_params['img_fc2_out'], model_params['dropout_p'], model_params['fine_tune_vis_module'])\n",
        "\n",
        "        self.fusion = torch.nn.Linear(\n",
        "            in_features=(model_params['text_fc2_out'] + model_params['img_fc2_out']), \n",
        "            out_features=model_params['fusion_output_size']\n",
        "        )\n",
        "        self.fc = torch.nn.Linear(\n",
        "            in_features=model_params['fusion_output_size'], \n",
        "            out_features=6\n",
        "        )\n",
        "        self.dropout = torch.nn.Dropout(model_params['dropout_p'])\n",
        "\n",
        "\n",
        "    def forward(self, text, image, label=None):\n",
        "\n",
        "        ## Pass the text input to Bert encoder \n",
        "        text_features = self.text_encoder(text[0], text[1])\n",
        "\n",
        "        ## Pass the image input \n",
        "        image_features = self.vision_encode(image)\n",
        "\n",
        "        ## concatenating Image and text \n",
        "        combined_features = torch.cat(\n",
        "            [text_features, image_features], dim=1\n",
        "        )        \n",
        "\n",
        "        combined_features = self.dropout(combined_features)\n",
        "\n",
        "        fused = self.dropout(\n",
        "            torch.nn.functional.relu(\n",
        "            self.fusion(combined_features)\n",
        "            )\n",
        "        )\n",
        "\n",
        "        prediction = self.fc(fused)\n",
        "\n",
        "        return prediction      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRh7qxtchIL0"
      },
      "outputs": [],
      "source": [
        "\n",
        "class RobotIntensionDataset(Dataset):\n",
        "\n",
        "    def __init__(self, df, root_dir, image_transform, tokenizer, MAX_LEN):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with text and img name.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.csv_data = df\n",
        "        self.root_dir = root_dir\n",
        "        self.image_transform = image_transform\n",
        "        self.tokenizer_bert = tokenizer\n",
        "        self.MAX_LEN = MAX_LEN\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.csv_data.shape[0]\n",
        "    \n",
        "    def pre_processing_BERT(self, sent):\n",
        "        # Create empty lists to store outputs\n",
        "        input_ids = []\n",
        "        attention_mask = []\n",
        "        \n",
        "        encoded_sent = self.tokenizer_bert.encode_plus(\n",
        "            text= sent.lower(),  # Preprocess sentence\n",
        "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
        "            max_length= self.MAX_LEN,                  # Max length to truncate/pad\n",
        "            padding='max_length',         # Pad sentence to max length\n",
        "            # return_tensors='pt',           # Return PyTorch tensor\n",
        "            return_attention_mask=True,      # Return attention mask\n",
        "            truncation=True\n",
        "            )\n",
        "        \n",
        "        input_ids = encoded_sent.get('input_ids')\n",
        "        attention_mask = encoded_sent.get('attention_mask')\n",
        "        \n",
        "        # Convert lists to tensors\n",
        "        input_ids = torch.tensor(input_ids)\n",
        "        attention_mask = torch.tensor(attention_mask)\n",
        "        \n",
        "        return input_ids, attention_mask\n",
        "     \n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        \n",
        "        img_name = self.root_dir + list(self.csv_data['image_path'])[idx]+'.jpg'\n",
        "        \n",
        "        image = Image.open(img_name).convert(\"RGB\")\n",
        "        \n",
        "        image = self.image_transform(image)\n",
        "        \n",
        "        text = list(self.csv_data['gpt3_intension_wd'])[idx]\n",
        "        \n",
        "        tensor_input_id, tensor_input_mask = self.pre_processing_BERT(text)\n",
        "\n",
        "        label = list(self.csv_data['label'])[idx]\n",
        "        label = torch.tensor(label)\n",
        "\n",
        "        sample = {'image': image, 'BERT_ip': [tensor_input_id, tensor_input_mask], 'label':label}\n",
        "\n",
        "        return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLDwBsyGWI-J",
        "outputId": "4f5545a6-e94f-430f-d979-1be1efb425bc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "image_transform = torchvision.transforms.Compose(\n",
        "    [\n",
        "        torchvision.transforms.Resize(size=(224, 224)),\n",
        "        torchvision.transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]\n",
        ")\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "MAX_LEN = 500\n",
        "NUM_OF_CLASSES = 6\n",
        "root_dir = \"./\"\n",
        "\n",
        "# Run function `preprocessing_for_bert` on the dataset\n",
        "transformed_dataset_train = RobotIntensionDataset(df_train, root_dir, image_transform, tokenizer, MAX_LEN)\n",
        "\n",
        "transformed_dataset_val = RobotIntensionDataset(df_val, root_dir, image_transform, tokenizer, MAX_LEN)\n",
        "\n",
        "train_dataloader = DataLoader(transformed_dataset_train, batch_size=12,\n",
        "                        shuffle=True, num_workers=0)\n",
        "\n",
        "val_dataloader = DataLoader(transformed_dataset_val, batch_size=12,\n",
        "                        shuffle=True, num_workers=0)\n",
        "\n",
        "parameter_dict_model={\n",
        "    'text_fc2_out': 32, \n",
        "    'text_fc1_out': 128, \n",
        "    'dropout_p': 0.4, \n",
        "    'fine_tune_text_module': True,\n",
        "    'img_fc1_out': 128, \n",
        "    'img_fc2_out': 32, \n",
        "    'dropout_p': 0.4, \n",
        "    'fine_tune_vis_module': True,\n",
        "    'fusion_output_size': 35\n",
        "}\n",
        "\n",
        "parameter_dict_opt={'l_r': 3e-5,\n",
        "                    'eps': 1e-8\n",
        "                    }\n",
        "\n",
        "\n",
        "EPOCHS = 50\n",
        "\n",
        "final_model = LanguageAndVisionConcat(parameter_dict_model)\n",
        "\n",
        "final_model = final_model.to(device) \n",
        "\n",
        "# Create the optimizer\n",
        "optimizer = AdamW(final_model.parameters(),\n",
        "                  lr=parameter_dict_opt['l_r'],\n",
        "                  eps=parameter_dict_opt['eps'])\n",
        "\n",
        "# Total number of training steps\n",
        "total_steps = len(train_dataloader) * EPOCHS\n",
        "\n",
        "# Set up the learning rate scheduler\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps=0, # Default value\n",
        "                                            num_training_steps=total_steps)\n",
        "\n",
        "\n",
        "## Instantiate the tensorboard summary writer\n",
        "writer = SummaryWriter('runs/multi_att_exp3')\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "267JqGjnqXDO"
      },
      "outputs": [],
      "source": [
        "def train(model, loss_fn, optimizer, scheduler, train_dataloader, val_dataloader=None, epochs=4, evaluation=False, device='cpu', param_dict_model=None, param_dict_opt=None, save_best=False, file_path='./saved_models/best_model.pt', writer=None):\n",
        "    \"\"\"Train the BertClassifier model.\n",
        "    \"\"\"\n",
        "    # Start training loop\n",
        "    best_acc_val = 0\n",
        "    print(\"Start training...\\n\")\n",
        "    for epoch_i in range(epochs):\n",
        "        # =======================================\n",
        "        #               Training\n",
        "        # =======================================\n",
        "        # Print the header of the result table\n",
        "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
        "        print(\"-\"*70)\n",
        "\n",
        "        # Measure the elapsed time of each epoch\n",
        "        t0_epoch, t0_batch = time.time(), time.time()\n",
        "\n",
        "        # Reset tracking variables at the beginning of each epoch\n",
        "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
        "\n",
        "        # Put the model into the training mode\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch_counts +=1\n",
        "            # Load batch to GPU\n",
        "            img_ip , text_ip, label = batch[\"image\"], batch[\"BERT_ip\"], batch['label']\n",
        "            \n",
        "            b_input_ids, b_attn_mask = tuple(t.to(device) for t in text_ip)\n",
        "            \n",
        "            imgs_ip = img_ip.to(device)\n",
        "            \n",
        "            b_labels = label.to(device)\n",
        "\n",
        "            # Zero out any previously calculated gradients\n",
        "            model.zero_grad()\n",
        "\n",
        "            # Perform a forward pass. This will return logits.\n",
        "            logits = model(text=[b_input_ids, b_attn_mask], image=imgs_ip, label=b_labels)\n",
        "\n",
        "            # Compute loss and accumulate the loss values\n",
        "            loss = loss_fn(logits, b_labels)\n",
        "            batch_loss += loss.item()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and the learning rate\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            \n",
        "#             break \n",
        "            # Print the loss values and time elapsed for every 20 batches\n",
        "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
        "                # Calculate time elapsed for 20 batches\n",
        "                time_elapsed = time.time() - t0_batch\n",
        "\n",
        "                # Print training results\n",
        "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
        "                \n",
        "                ## Write onto tensorboard\n",
        "                if writer != None:\n",
        "                    writer.add_scalar('Training Loss', (batch_loss / batch_counts), epoch_i*len(train_dataloader)+step)\n",
        "                \n",
        "                # Reset batch tracking variables\n",
        "                batch_loss, batch_counts = 0, 0\n",
        "                t0_batch = time.time()\n",
        "\n",
        "        # Calculate the average loss over the entire training data\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "        print(\"-\"*70)\n",
        "        # =======================================\n",
        "        #               Evaluation\n",
        "        # =======================================\n",
        "        if evaluation == True:\n",
        "            # After the completion of each training epoch, measure the model's performance\n",
        "            # on our validation set.\n",
        "            val_loss, val_accuracy = evaluate(model, loss_fn, val_dataloader, device)            \n",
        "            \n",
        "            # Print performance over the entire training data\n",
        "            time_elapsed = time.time() - t0_epoch\n",
        "            \n",
        "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
        "            print(\"-\"*70)\n",
        "            \n",
        "            ## Write onto tensorboard\n",
        "            if writer != None:\n",
        "                writer.add_scalar('Validation Loss', val_loss, epoch_i+1)\n",
        "                writer.add_scalar('Validation Accuracy', val_accuracy, epoch_i+1)\n",
        "            \n",
        "            # Save the best model\n",
        "            if save_best: \n",
        "                if val_accuracy > best_acc_val:\n",
        "                    best_acc_val = val_accuracy\n",
        "                    torch.save({\n",
        "                                'epoch': epoch_i+1,\n",
        "                                'model_params': param_dict_model,\n",
        "                                'opt_params': param_dict_opt,\n",
        "                                'model_state_dict': model.state_dict(),\n",
        "                                'opt_state_dict': optimizer.state_dict(),\n",
        "                                'sch_state_dict': scheduler.state_dict()\n",
        "                               }, file_path)\n",
        "                    \n",
        "        print(\"\\n\")\n",
        "    \n",
        "    print(\"Training complete!\")\n",
        "    \n",
        "    \n",
        "    \n",
        "def evaluate(model, loss_fn, val_dataloader, device):\n",
        "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
        "    on our validation set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    val_accuracy = []\n",
        "    val_loss = []\n",
        "\n",
        "    # For each batch in our validation set...\n",
        "    for batch in val_dataloader:\n",
        "        img_ip , text_ip, label = batch[\"image\"], batch[\"BERT_ip\"], batch['label']\n",
        "            \n",
        "        b_input_ids, b_attn_mask = tuple(t.to(device) for t in text_ip)\n",
        "\n",
        "        imgs_ip = img_ip.to(device)\n",
        "\n",
        "        b_labels = label.to(device)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(text=[b_input_ids, b_attn_mask], image=imgs_ip, label=b_labels)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        val_loss.append(loss.item())\n",
        "\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "\n",
        "        # Calculate the accuracy rate\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
        "        val_accuracy.append(accuracy)\n",
        "\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    val_loss = np.mean(val_loss)\n",
        "    val_accuracy = np.mean(val_accuracy)\n",
        "\n",
        "    return val_loss, val_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1HiR3S9ltJO",
        "outputId": "92fa39c4-31b4-484f-b055-db52f3ed8a0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start training...\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   1    |   20    |   1.692396   |     -      |     -     |   96.16  \n",
            "   1    |   40    |   1.563202   |     -      |     -     |   92.65  \n",
            "   1    |   60    |   1.521665   |     -      |     -     |   87.39  \n",
            "   1    |   80    |   1.419043   |     -      |     -     |   87.42  \n",
            "   1    |   100   |   1.361218   |     -      |     -     |   86.92  \n",
            "   1    |   120   |   1.282339   |     -      |     -     |   80.81  \n",
            "   1    |   140   |   1.387449   |     -      |     -     |   85.20  \n",
            "   1    |   160   |   1.345350   |     -      |     -     |   83.23  \n",
            "   1    |   180   |   1.305800   |     -      |     -     |   81.83  \n",
            "   1    |   200   |   1.205654   |     -      |     -     |   78.50  \n",
            "   1    |   220   |   1.252229   |     -      |     -     |   81.26  \n",
            "   1    |   240   |   1.128689   |     -      |     -     |   92.07  \n",
            "   1    |   260   |   1.192022   |     -      |     -     |   76.25  \n",
            "   1    |   280   |   1.176282   |     -      |     -     |   80.38  \n",
            "   1    |   300   |   1.076567   |     -      |     -     |   75.27  \n",
            "   1    |   320   |   1.254072   |     -      |     -     |   73.14  \n",
            "   1    |   340   |   1.189375   |     -      |     -     |   73.32  \n",
            "   1    |   360   |   1.102769   |     -      |     -     |   66.52  \n",
            "   1    |   380   |   1.101387   |     -      |     -     |   66.87  \n",
            "   1    |   400   |   1.162133   |     -      |     -     |   73.32  \n",
            "   1    |   420   |   1.086727   |     -      |     -     |   67.74  \n",
            "   1    |   440   |   1.125947   |     -      |     -     |   65.86  \n",
            "   1    |   460   |   1.127437   |     -      |     -     |   62.81  \n",
            "   1    |   480   |   1.081353   |     -      |     -     |   63.67  \n",
            "   1    |   500   |   1.101049   |     -      |     -     |   64.57  \n",
            "   1    |   520   |   0.994159   |     -      |     -     |   62.04  \n",
            "   1    |   540   |   0.946485   |     -      |     -     |   64.74  \n",
            "   1    |   560   |   1.095601   |     -      |     -     |   60.77  \n",
            "   1    |   580   |   1.226620   |     -      |     -     |   60.33  \n",
            "   1    |   581   |   0.680526   |     -      |     -     |   0.55   \n",
            "----------------------------------------------------------------------\n",
            "   1    |    -    |   1.224181   |  0.866726  |   72.89   |  2490.09 \n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-fac2d857aefe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfinal_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_dict_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameter_dict_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_dict_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameter_dict_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./saved_models/best_model.pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-4035a17a9313>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loss_fn, optimizer, scheduler, train_dataloader, val_dataloader, epochs, evaluation, device, param_dict_model, param_dict_opt, save_best, file_path, writer)\u001b[0m\n\u001b[1;32m    106\u001b[0m                                 \u001b[0;34m'opt_state_dict'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                                 \u001b[0;34m'sch_state_dict'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                                }, file_path)\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0m_check_dill_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './saved_models/best_model.pt'"
          ]
        }
      ],
      "source": [
        "train(model=final_model, loss_fn=loss_fn, optimizer=optimizer, scheduler=scheduler, train_dataloader=train_dataloader, val_dataloader=val_dataloader, epochs=150, evaluation=True, device=device, param_dict_model=parameter_dict_model, param_dict_opt=parameter_dict_opt, save_best=True, file_path='./saved_models/best_model.pt', writer=writer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3msXBko3PFza"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}